# í…ìŠ¤íŠ¸ ë²¡í„° ìƒì„± 
text <- c("Crash dieting is not the best way to lose weight. http://bbc.in/1G0J4Agg",
          "A vegetarian diet excludes all animal flesh (meat, poultry, seafood).",
          "Economists surveyed by Refinitiv expect the economy added 160,000 jobs.")

library(tm)

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ 

#Verctorë¥¼ í†µí•´ ì½”í¼ìŠ¤ í˜•íƒœë¡œ ë§Œë“ ë‹¤ 
corpus.docs <- VCorpus(VectorSource(text))
lapply(corpus.docs, meta)      #ì½”í¼ìŠ¤ì—ì„œ meta ë¶€ë¶„ í™•ì¸ 
lapply(corpus.docs, content)   #ì½”í¼ìŠ¤ì—ì„œ content ë¶€ë¶„ í™•ì¸

#tmì— ì—†ëŠ” í•¨ìˆ˜ë¼ content_transformer ì‚¬ìš© ï¼ï¼ ì „ì²˜ë¦¬ í•˜ê¸°
corpus.docs <- tm_map(corpus.docs, content_transformer(tolower)) #ì†Œë¬¸ì ë³€í™˜

#stopwords í†µí•´ ë¶ˆìš©ì–´ ì œê±°
corpus.docs <- tm_map(corpus.docs, removeWords, stopwords('english')) 

#íŠ¹ì • íŒ¨í„´ì„ ê°€ì§€ëŠ” ë¬¸ìë¥¼ gsubë¡œ ì¶”ì¶œí•´ ë³€ìˆ˜ë¡œ ì €ì¥ 
myRemove <- content_transformer(function(x, pattern) 
{return(gsub(pattern,"",x))})

#ì—†ì• ê¸° 
corpus.docs <- tm_map(corpus.docs, myRemove, "(f|ht)tp\\S+\\s*") #í•¨ìˆ˜ë¥¼ ì´ìš©í•œ url ì œê±° pus.docs <- tm_map(corpus.docs, removePunctuation) #????ë¬¸ì¥ë¶€í˜¸ ì‚­ì œ corpus.docs, content)
corpus.d
corpus.docs[[1]]$content.docs <- tm_m <-orpus.docs, removeNumbers) #???? ??Áìˆ«ì ì‚­ì œ
corpus.docs <- tm_map(corpus.docs, stripWhitespace) #ì—¬ë°± ì‚­ì œ tm_map(corpus.docs, content_transformer(trimws)) #?Ø½?Æ® ?Õµ??? ??í…ìŠ¤íŠ¸ ì•ë’¤ ì—†ì• ê¸° ap(corpus.docs, stemDocument) #?î°£ ????
corpus.docì–´ê°„ ì¶”ì¶œ ap(corpus.docs, content_transformer(gsub),
                      pattern='economist', replacement='economi') #???Ç¾? Ã³??

corpus.ë™ì˜ì–´ ì²˜ë¦¬ me
######### DTM #########
ntTermMatrix(corpus.docs, 
                   control = list(wordLengths = c(2,Inf)))

nTerms(corpus.dtm)  #ë‹¨ì–´ 2ê°œ ì´ìƒ -> ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ 
n#ì´ë ‡ê²Œ ë˜ë©´ 3ê°œì˜ document (=ë§¨ìœ„ì—ì„œ ìƒì„±í•œê±° 3ê°œ), terms 19ê°œ ìƒê¹€ 
# Non-/sparse entries: 20/37 -> ì´ 3x19=57ì—ì„œ 

Docs(corpus.dtm)
T  # ì´ ë‹¨ì–´ ìˆ˜ 
nDocs(corpus.dtm)   # ì´ ë¬¸ì„œ ìˆ˜ Docs(corpus.dtm)
r   #ì–´ë–¤ ë‹¨ì–´ë“¤ì´ í¬í•¨ë˜ëŠ”ì§€ ow.names(corpus.dt  # [1] "1" "2" "3"m
#docsì— ì´ë¦„ ë¶€ì—¬ 
) <- c("BBC", "CNN", "FoX")

inspect(corpus.dtm)

#term ì¼ë¶€ ë³´ê¸° 
inspect(corpus.dtm[1
#termë§Œ ì¼ë¶€ ë³´ê¸° -> 10:19
:3 ,10:19])



### Tidy text ?????? ?????? ?? 
t í˜•ì‹ì˜ ë°ì´í„° ì…‹ ì´ìš©í•´ì„œ ~ eting is not the best way to lose weight. http://bbc.in/1G0J4Agg",
          "A vegetarian diet excludes all animal flesh (meat, poultry, seafood).",
          "Economists surveyed by Refinitiv expect the economy added 160,000 jobs.")
source <- c("BBC", "CNN", "FOX")

library(dplyr)
library(tidytext)
library(SnowballC)

text.df <- tibble(so
# ë²¡í„° -> í‹°ë¸” í˜•íƒœë¡œ ë§Œë“¦ 
urce=source, text=text)
text.df

text.df$text <- gsub("(f|ht)tp\\S+\\s*", "", text.df$text) #url ??Á¦
text.df$text <-ì‚­ì œ \d+", "", text.df$text) #???? ??Á¦
tidy.docs <- tìˆ«ì ì‚­ì œ  
unnest_tokens(output=word, input=text) %>%  #??Å«È­ 
  anti_join(stop_worí† í°í™” -> wordë¡œ ë°”ë€œ ="word") %>%  #?Ò¿??? ????À» È°???? ?Ò¿??? ë¶ˆìš©ì–´ ì‚¬ì „ì„ í™œìš©í•œ ë¶ˆìš©ì–´ ì œê±°  ???? 
tidy.docs$word <- gsub("\ì–´ê°„ ì¶”ì¶œ t
idy.docs$word) #????Á¦??
tidy.docs$word <- gsub("ecoê³µë°± ì œê±° onomi", tidy.docs$word) #???Ç¾? Ã³??


tidy.dtm <- tidy.docs %>% ë™ì˜ì–´ ì²˜ë¦¬ e, word) ocs

tidy.d%>% 
  cast_dtm(document = source, term = word, value = n)
tidy.dtm

Terms(tidy.dtm)
Docs(tidy.dtm)
inspect(tidy.dtm[1:2,3:5])
tidy.dtm <-as.data.frame(inspect(tidy.dt






m))

tidy(tidy.dtm)

tidy.dtm <- as.data.frame(tidy.dtm)
tity.tdm <- t(tidy.dtm)






















